#!/bin/bash

# --- Configuration ---
TEMPLATES_DIR="templates"
HOMEWORKS_ROOT_DIR="homeworks"

# --- Argument Handling ---
if [ -z "$1" ]; then
    echo "Usage: $0 <homework_number>"
    echo "Example: $0 1"
    exit 1
fi
HW_NUM=$1

# --- Target Paths ---
HW_DIR="${HOMEWORKS_ROOT_DIR}/hw${HW_NUM}"
SRC_DIR="$HW_DIR/src"
TARGET_MAKEFILE="$HW_DIR/Makefile"
TARGET_CMAKELISTS="$HW_DIR/CMakeLists.txt"
TARGET_C_SRC="$SRC_DIR/template.c"
TARGET_CU_SRC="$SRC_DIR/template.cu"
TARGET_SUMMARY="$HW_DIR/summary.md"

# --- Template Paths ---
cmake_template_path="$TEMPLATES_DIR/CMakeLists.txt.template"
c_template_path="$TEMPLATES_DIR/template.c.template"
cu_template_path="$TEMPLATES_DIR/template.cu.template"

# --- Content Generation Functions ---

# Function to generate the Makefile content (Ensures correct TABs)
generate_makefile_content() {
    local target_file="$1"
    printf '%s\n' \
'# Makefile generated by scaffold_hw.sh - REQUIRED FOR SUBMISSION' \
'# Adjust CC/NVCC/CFLAGS/LDFLAGS/LIBS as needed per assignment' \
'' \
'# Default is MPI C compilation' \
'CC = mpicc' \
'NVCC = nvcc' \
'CXX = mpiCC # For C++ MPI' \
'' \
'# Common flags (adjust -std as needed)' \
'CFLAGS = -Wall -Wextra -std=c11 -O2' \
'CXXFLAGS = -Wall -Wextra -std=c++11 -O2' \
'NVCCFLAGS = -O2 -arch=sm_75 # IMPORTANT: Set appropriate compute capability for your target GPUs' \
'' \
'# Libraries' \
'LDFLAGS = -lm # Link math library by default' \
'CUDA_LIBS = -lcudart # Basic CUDA runtime' \
'' \
'# Executable name MUST be "template" for submission' \
'EXE = template' \
'' \
'# --- Determine source file type ---' \
'# Simple check for .cu extension (adjust if using .cpp)' \
'SRC_CU := $(wildcard src/*.cu)' \
'SRC_C := $(wildcard src/*.c)' \
'SRC_CPP := $(wildcard src/*.cpp)' \
'' \
'# --- Build Rules ---' \
'ifeq ($(SRC_CU),)' \
'# --- MPI C/C++ Build ---' \
'ifeq ($(SRC_CPP),)' \
'# C Build' \
'SRC = $(SRC_C)' \
'COMPILER = $(CC)' \
'FLAGS = $(CFLAGS)' \
'else' \
'# C++ Build' \
'SRC = $(SRC_CPP)' \
'COMPILER = $(CXX)' \
'FLAGS = $(CXXFLAGS)' \
'endif' \
'' \
'all: $(EXE)' \
'' \
'$(EXE): $(SRC)' \
'# Note: The next line MUST start with a TAB character' \
$'\t''$(COMPILER) $(FLAGS) $^ -o $@ $(LDFLAGS)' \
'else' \
'# --- MPI + CUDA Build ---' \
'# Assumes MPI calls might be in .cu or linked C/C++ files if structure is complex' \
'# This Makefile might need significant adjustment for complex MPI+CUDA builds.' \
'# CMake is often preferred for development in such cases.' \
'# THIS IS A BASIC EXAMPLE FOR SUBMISSION PURPOSES if prof requires Makefile for CUDA too.' \
'SRC = $(SRC_CU)' \
'OBJS = $(patsubst src/%.cu, build/%.o, $(SRC))' \
'' \
'all: $(EXE)' \
'' \
'# Ensure build directory exists (executed during make processing)' \
'# This command does not need a leading tab here as part of $(shell ...)' \
'MKDIR_OUT := $(shell mkdir -p build)' \
'' \
'build/%.o: src/%.cu' \
'# Note: The next line MUST start with a TAB character' \
$'\t''$(NVCC) $(NVCCFLAGS) -dc $< -o $@' \
'' \
'$(EXE): $(OBJS)' \
'# Note: The next line MUST start with a TAB character' \
$'\t''$(CC) $(FLAGS) $^ -o $@ $(LDFLAGS) $(CUDA_LIBS) -L$(CUDA_HOME)/lib64' \
'endif' \
'' \
'clean:' \
'# Note: The next line MUST start with a TAB character' \
$'\t''rm -rf $(EXE) build/ *.o *.tgz' > "$target_file" # Overwrite target file
}

# Function to generate default C template content
generate_c_template_content() {
     local target_file="$1"
     printf '%s\n' \
'/*' \
' * Basic MPI Template (for HW 1-3)' \
' * CS485 GPU cluster programming' \
' * Spring 2025' \
' */' \
'' \
'#include <stdio.h>' \
'#include <stdlib.h>' \
'#include <mpi.h>' \
'#include <time.h> // For timing, if needed or srand' \
'' \
'// --- Constants ---' \
'// #define ROOT 0 // Common practice' \
'' \
'// --- Function Prototypes ---' \
'// Add prototypes for your functions here' \
'' \
'// --- Main Function ---' \
'int main(int argc, char *argv[]) {' \
'    int rank, size;' \
'' \
'    // Initialize the MPI environment' \
'    MPI_Init(&argc, &argv);' \
'' \
'    // Get the number of processes' \
'    MPI_Comm_size(MPI_COMM_WORLD, &size);' \
'' \
'    // Get the rank of the process' \
'    MPI_Comm_rank(MPI_COMM_WORLD, &rank);' \
'' \
'    // Optional: Get the name of the processor' \
'    char processor_name[MPI_MAX_PROCESSOR_NAME];' \
'    int name_len;' \
'    MPI_Get_processor_name(processor_name, &name_len);' \
'' \
'    if (rank == 0) {' \
'        printf("MPI World Size: %d\n", size);' \
'    }' \
'' \
'    printf("Process %d of %d on %s\n", rank, size, processor_name);' \
'' \
'    // --- Argument Parsing ---' \
'    int problem_size = 0; // Example: Default problem size' \
'    if (argc > 1) {' \
'        problem_size = atoi(argv[1]);' \
'        if (rank == 0) {' \
'             printf("Problem size input: %d\n", problem_size);' \
'        }' \
'    } else {' \
'        if (rank == 0) {' \
'            // It'\''s often better to print usage and exit gracefully than abort' \
'            fprintf(stderr, "Usage: mpirun -np <num_procs> %s <problem_size>\n", argv[0]);' \
'        }' \
'         MPI_Finalize(); // Finalize before exiting' \
'         return 1; // Indicate error' \
'        // MPI_Abort(MPI_COMM_WORLD, 1); // Alternative, more forceful exit' \
'    }' \
'' \
'    // --- Your Homework Logic Starts Here ---' \
'' \
'    // Example: Allocate memory, distribute data, compute, gather results...' \
'' \
'' \
'    // --- Your Homework Logic Ends Here ---' \
'' \
'' \
'    // Finalize the MPI environment.' \
'    MPI_Finalize();' \
'' \
'    return 0; // Indicate success' \
'}' \
'' \
'// --- Helper Function Definitions ---' \
'/* Add your functions like init_data, mat_mult, check_result here */' \
'' \
'/* Example:' \
'void init_data(double* data, int size) {' \
'    // Implementation' \
'}' \
'*/' \
'' \
'/*' \
'End of file' \
'*/' > "$target_file"
}

# Function to generate default CUDA template content
generate_cu_template_content() {
    local target_file="$1"
    printf '%s\n' \
'/*' \
' * Basic MPI + CUDA Template (for HW 4+)' \
' * CS485 GPU cluster programming' \
' * Spring 2025' \
' *' \
' * Note: Often written as C++, but can be adapted for C + CUDA runtime API.' \
' */' \
'#include <stdio.h>' \
'#include <stdlib.h>' \
'#include <mpi.h>' \
'#include <cuda_runtime.h>' \
'#include <time.h> // For timing' \
'' \
'// --- Utility Macros ---' \
'// Macro for checking CUDA errors (Essential!)' \
'#define CUDA_CHECK(call) do { \' \
'    cudaError_t err = call; \' \
'    if (err != cudaSuccess) { \' \
'        fprintf(stderr, "CUDA Error in %s at line %d: %s (%d)\n", \' \
'                __FILE__, __LINE__, cudaGetErrorString(err), err); \' \
'        MPI_Abort(MPI_COMM_WORLD, EXIT_FAILURE); \' \
'    } \' \
'} while (0)' \
'' \
'// --- Kernel Definitions ---' \
'// Forward declaration or include separate .cuh file' \
'// __global__ void myKernel(/* parameters */);' \
'' \
'' \
'// --- Main Function ---' \
'int main(int argc, char *argv[]) {' \
'    int rank, size;' \
'    int device_id = 0; // Default GPU device ID' \
'' \
'    // Initialize the MPI environment' \
'    MPI_Init(&argc, &argv);' \
'' \
'    // Get the number of processes & rank' \
'    MPI_Comm_size(MPI_COMM_WORLD, &size);' \
'    MPI_Comm_rank(MPI_COMM_WORLD, &rank);' \
'' \
'    // --- GPU Selection & Verification ---' \
'    int num_devices = 0;' \
'    CUDA_CHECK(cudaGetDeviceCount(&num_devices));' \
'    if (num_devices == 0) {' \
'        fprintf(stderr, "[Rank %d] No CUDA-capable devices found. Aborting.\n", rank);' \
'        MPI_Abort(MPI_COMM_WORLD, EXIT_FAILURE);' \
'    }' \
'    // Simple device assignment (can be more sophisticated)' \
'    device_id = rank % num_devices;' \
'    CUDA_CHECK(cudaSetDevice(device_id));' \
'' \
'    cudaDeviceProp deviceProp;' \
'    CUDA_CHECK(cudaGetDeviceProperties(&deviceProp, device_id));' \
'    if (rank == 0) { // Print device info once per node (ideally handle shared memory nodes better)' \
'         printf("[Rank %d using GPU %d] %s | Compute Capability: %d.%d | Total Global Mem: %zu MB\n",' \
'                rank, device_id, deviceProp.name, deviceProp.major, deviceProp.minor,' \
'                deviceProp.totalGlobalMem / (1024 * 1024));' \
'    }' \
'' \
'' \
'    // --- Argument Parsing ---' \
'    int problem_size = 0; // Example' \
'    if (argc > 1) {' \
'        problem_size = atoi(argv[1]);' \
'        if (rank == 0) {' \
'             printf("Problem size input: %d\n", problem_size);' \
'        }' \
'    } else {' \
'        if (rank == 0) {' \
'            fprintf(stderr, "Usage: mpirun -np <num_procs> %s <problem_size>\n", argv[0]);' \
'        }' \
'         MPI_Finalize();' \
'         return 1;' \
'    }' \
'' \
'' \
'    // --- Your Homework Logic Starts Here ---' \
'' \
'    // Example MPI + CUDA workflow outline:' \
'    // 1. Root process (rank 0) reads/generates initial host data.' \
'    // 2. Determine data distribution (how much data per rank).' \
'    // 3. Distribute data from root to all ranks using MPI (e.g., MPI_Scatter, MPI_Bcast).' \
'    // 4. Each rank allocates memory on its assigned GPU (CUDA_CHECK(cudaMalloc(...))).' \
'    // 5. Copy relevant data portion from host buffer to device buffer (CUDA_CHECK(cudaMemcpy(..., cudaMemcpyHostToDevice))).' \
'    // 6. Define kernel launch parameters (gridDim, blockDim).' \
'    // 7. Launch the kernel(s) on the GPU (myKernel<<<gridDim, blockDim>>>(...)). CUDA_CHECK(cudaGetLastError());' \
'    // 8. Synchronize device if necessary before copying results back (CUDA_CHECK(cudaDeviceSynchronize())).' \
'    // 9. Copy results from device buffer to host buffer (CUDA_CHECK(cudaMemcpy(..., cudaMemcpyDeviceToHost))).' \
'    // 10. Gather results from all ranks to the root process using MPI (e.g., MPI_Gather, MPI_Reduce).' \
'    // 11. Root process might perform final verification or output.' \
'    // 12. Free GPU memory (CUDA_CHECK(cudaFree(...))).' \
'    // 13. Free host memory.' \
'' \
'' \
'    // --- Your Homework Logic Ends Here ---' \
'' \
'' \
'    // Finalize the MPI environment.' \
'    MPI_Finalize();' \
'' \
'    // Optional: Reset device context if needed' \
'    // CUDA_CHECK(cudaDeviceReset());' \
'' \
'    return 0; // Indicate success' \
'}' \
'' \
'' \
'// --- Helper Function Definitions ---' \
'/* Add your host helper functions here */' \
'' \
'/* Example Kernel Implementation:' \
'__global__ void myKernel(float *input, float *output, int size) {' \
'    int idx = blockIdx.x * blockDim.x + threadIdx.x;' \
'    if (idx < size) {' \
'        // Do some computation' \
'        output[idx] = input[idx] * 2.0f;' \
'    }' \
'}' \
'*/' \
'' \
'/*' \
'End of file' \
'*/' > "$target_file"
}

# Function to generate default CMakeLists template content
generate_cmakelists_template_content() {
    local target_file="$1"
    printf '%s\n' \
'# CMake build file template for MPI+CUDA assignments (HW4+)' \
'# This is used by test_hw.sh for local development/testing.' \
'# The simpler Makefile in the homework root is used for submission packaging.' \
'' \
'cmake_minimum_required(VERSION 3.18 FATAL_ERROR) # MPI/CUDA needs relatively recent CMake' \
'' \
'# Project definition - enabling C, C++, and CUDA languages' \
'project(HomeworkProject LANGUAGES C CXX CUDA)' \
'' \
'message(STATUS "Project Name: ${PROJECT_NAME}")' \
'message(STATUS "Source Directory: ${CMAKE_CURRENT_SOURCE_DIR}") # Should be homeworks/hwX' \
'message(STATUS "Binary Directory: ${CMAKE_CURRENT_BINARY_DIR}") # Should be homeworks/hwX/build' \
'' \
'# --- Find Required Packages ---' \
'' \
'# Find MPI (requesting C and CXX components)' \
'find_package(MPI REQUIRED COMPONENTS C CXX)' \
'message(STATUS "MPI Found: ${MPI_FOUND}")' \
'if(MPI_FOUND)' \
'    message(STATUS "MPI C Compiler: ${MPI_C_COMPILER}")' \
'    message(STATUS "MPI CXX Compiler: ${MPI_CXX_COMPILER}")' \
'endif()' \
'' \
'# Find CUDA Toolkit' \
'# Set minimum C++ standard required by CUDA code if applicable' \
'# set(CMAKE_CUDA_STANDARD 11) # Or 14, 17' \
'# set(CMAKE_CUDA_STANDARD_REQUIRED ON)' \
'# set(CMAKE_CUDA_EXTENSIONS OFF) # Prefer standard CUDA' \
'' \
'# Select target compute architectures (Virtual AND Real recommended)' \
'# Example: sm_75 (Turing), sm_86 (Ampere for 3090). Adjust based on your target hardware.' \
'# Consult NVIDIA docs or deviceQuery for capabilities.' \
'# Providing multiple ensures broader compatibility if needed.' \
'set(CMAKE_CUDA_ARCHITECTURES "75;86" CACHE STRING "CUDA architectures (e.g., 75;86)")' \
'message(STATUS "Targeting CUDA Architectures: ${CMAKE_CUDA_ARCHITECTURES}")' \
'' \
'# Use the modern FindCUDAToolkit module' \
'find_package(CUDAToolkit REQUIRED)' \
'message(STATUS "CUDA Toolkit Found: ${CUDAToolkit_FOUND}")' \
'if(CUDAToolkit_FOUND)' \
'    message(STATUS "CUDA Toolkit Include Dirs: ${CUDAToolkit_INCLUDE_DIRS}")' \
'    message(STATUS "CUDA Libraries: ${CUDAToolkit_LIBRARIES}") # Usually cudart' \
'endif()' \
'' \
'' \
'# --- Add Executable ---' \
'# Assume source code is in a '\''src'\'' subdirectory relative to this CMakeLists.txt' \
'# Glob files (simple approach) or list them explicitly' \
'file(GLOB SOURCES "src/*.c" "src/*.cpp" "src/*.cu")' \
'' \
'if(NOT SOURCES)' \
'    message(FATAL_ERROR "No source files found in '\''src/'\'' directory relative to $(pwd)!")' \
'endif()' \
'message(STATUS "Source files: ${SOURCES}")' \
'' \
'# Executable name MUST be '\''template'\'' to match course requirements' \
'add_executable(template ${SOURCES})' \
'' \
'# --- Link Libraries ---' \
'# Link MPI libraries using imported targets (preferred modern approach)' \
'# Link both C and CXX libraries found by find_package(MPI)' \
'target_link_libraries(template PRIVATE MPI::MPI_C MPI::MPI_CXX)' \
'message(STATUS "Linking MPI libraries...")' \
'' \
'# Link CUDA runtime library (cudart) - Essential for most CUDA apps' \
'# Add other CUDA libs if needed: CUDA::cublas, CUDA::cufft, etc.' \
'target_link_libraries(template PRIVATE CUDA::cudart)' \
'message(STATUS "Linking CUDA runtime library...")' \
'' \
'# Link math library (libm) if needed (e.g., for sqrt, sin, etc.)' \
'target_link_libraries(template PRIVATE m)' \
'message(STATUS "Linking math library...")' \
'' \
'# --- Set Properties (Optional but Recommended) ---' \
'# Set C/C++/CUDA standard if needed/desired' \
'# set_target_properties(template PROPERTIES' \
'#     C_STANDARD 11' \
'#     CXX_STANDARD 17' \
'#     CUDA_STANDARD 17' \
'# )' \
'' \
'# Add common compiler flags (warnings, optimization)' \
'# Use generator expressions to apply flags based on language' \
'target_compile_options(template PRIVATE' \
'    $<$<COMPILE_LANGUAGE:C>:-Wall -Wextra -O2>' \
'    $<$<COMPILE_LANGUAGE:CXX>:-Wall -Wextra -O2>' \
'    # $<$<COMPILE_LANGUAGE:CUDA>:-Wall -Wextra> # Apply warnings via NVCC host compiler if desired' \
')' \
'' \
'message(STATUS "CMake configuration finished for target '\''template'\''")' > "$target_file"
}

# --- Stage 1: Verify/Create Template Files ---
echo "--- Verifying/Creating Template Files in $TEMPLATES_DIR ---"
mkdir -p "$TEMPLATES_DIR" # Ensure templates directory exists

if [ ! -f "$c_template_path" ]; then
    echo "Template file '$c_template_path' not found. Creating default..."
    generate_c_template_content "$c_template_path" || { echo "Error creating C template."; exit 1; }
else
    echo "Template file '$c_template_path' found."
fi

if [ ! -f "$cu_template_path" ]; then
    echo "Template file '$cu_template_path' not found. Creating default..."
    generate_cu_template_content "$cu_template_path" || { echo "Error creating CU template."; exit 1; }
else
    echo "Template file '$cu_template_path' found."
fi

if [ ! -f "$cmake_template_path" ]; then
    echo "Template file '$cmake_template_path' not found. Creating default..."
    generate_cmakelists_template_content "$cmake_template_path" || { echo "Error creating CMakeLists template."; exit 1; }
else
    echo "Template file '$cmake_template_path' found."
fi
echo "--- Template Verification Complete ---"
echo ""


# --- Stage 2: Scaffold Homework Directory ---
echo "--- Scaffolding Homework ${HW_NUM} in ${HW_DIR} ---"

# Check if homework directory already exists
if [ -d "$HW_DIR" ]; then
    echo "Directory '$HW_DIR' already exists. Checking for missing files..."
    mkdir -p "$SRC_DIR" # Ensure src dir exists within it

    # Check and create missing files individually
    if [ ! -f "$TARGET_MAKEFILE" ]; then
        echo "Makefile missing in '$HW_DIR'. Generating..."
        generate_makefile_content "$TARGET_MAKEFILE" || { echo "Error generating Makefile."; exit 1; }
    fi

    if [ ! -f "$TARGET_SUMMARY" ]; then
         echo "Summary file missing in '$HW_DIR'. Creating empty..."
         touch "$TARGET_SUMMARY"
         echo "# Summary for Homework ${HW_NUM}" > "$TARGET_SUMMARY"
    fi

    # Check for source file based on HW number
    if [ "$HW_NUM" -ge 1 ] && [ "$HW_NUM" -le 3 ]; then
        if [ ! -f "$TARGET_C_SRC" ]; then
            echo "Source file '$TARGET_C_SRC' missing. Copying from template..."
            cp "$c_template_path" "$TARGET_C_SRC" || { echo "Error copying C template."; exit 1; }
        fi
    elif [ "$HW_NUM" -ge 4 ]; then
        # Check for CMakeLists only for HW 4+
        if [ ! -f "$TARGET_CMAKELISTS" ]; then
             echo "CMakeLists.txt missing in '$HW_DIR'. Copying from template..."
             cp "$cmake_template_path" "$TARGET_CMAKELISTS" || { echo "Error copying CMakeLists template."; exit 1; }
        fi
        # Check for .cu source file for HW 4+
        if [ ! -f "$TARGET_CU_SRC" ]; then
            echo "Source file '$TARGET_CU_SRC' missing. Copying from template..."
            cp "$cu_template_path" "$TARGET_CU_SRC" || { echo "Error copying CU template."; exit 1; }
        fi
    fi
    echo "Checked existing directory '$HW_DIR'."

else
    # Homework directory does not exist, create everything
    echo "Directory '$HW_DIR' not found. Creating new structure..."
    mkdir -p "$SRC_DIR" || { echo "Failed to create directory $SRC_DIR"; exit 1; }

    # Generate/Copy all required files
    echo "Generating Makefile..."
    generate_makefile_content "$TARGET_MAKEFILE" || { echo "Error generating Makefile."; exit 1; }

    echo "Creating summary file..."
    touch "$TARGET_SUMMARY"
    echo "# Summary for Homework ${HW_NUM}" > "$TARGET_SUMMARY"

    # Copy appropriate source and CMakeLists (if needed)
    if [ "$HW_NUM" -ge 1 ] && [ "$HW_NUM" -le 3 ]; then
        echo "Copying C source template..."
        cp "$c_template_path" "$TARGET_C_SRC" || { echo "Error copying C template."; exit 1; }
    elif [ "$HW_NUM" -ge 4 ]; then
        echo "Copying CMakeLists template..."
        cp "$cmake_template_path" "$TARGET_CMAKELISTS" || { echo "Error copying CMakeLists template."; exit 1; }
        echo "Copying CU source template..."
        cp "$cu_template_path" "$TARGET_CU_SRC" || { echo "Error copying CU template."; exit 1; }
        # Optional: Rename if using C++ (.cpp)
        # mv "$TARGET_CU_SRC" "${SRC_DIR}/template.cpp"
    else
        echo "Error: Invalid Homework number ${HW_NUM}."
        exit 1 # Should have been caught earlier, but defensive check
    fi
    echo "Created new directory '$HW_DIR' and populated files."

fi

echo "--- Scaffolding complete for Homework ${HW_NUM} ---"